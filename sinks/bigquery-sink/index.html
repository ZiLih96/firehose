<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-sinks/bigquery-sink">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v0.0.0-5124">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XXX"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-XXX",{})</script><title data-rh="true">BigQuery | Firehose</title><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://odpf.github.io//firehose/sinks/bigquery-sink"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="BigQuery | Firehose"><meta data-rh="true" name="description" content="Bigquery Sink has several responsibilities, first creation of bigquery table and dataset when they are not exist, second update the bigquery table schema based on the latest protobuf schema, third translate protobuf messages into bigquery records and insert them to bigquery tables."><meta data-rh="true" property="og:description" content="Bigquery Sink has several responsibilities, first creation of bigquery table and dataset when they are not exist, second update the bigquery table schema based on the latest protobuf schema, third translate protobuf messages into bigquery records and insert them to bigquery tables."><link data-rh="true" rel="icon" href="/firehose/assets/favicon.ico"><link data-rh="true" rel="canonical" href="https://odpf.github.io//firehose/sinks/bigquery-sink"><link data-rh="true" rel="alternate" href="https://odpf.github.io//firehose/sinks/bigquery-sink" hreflang="en"><link data-rh="true" rel="alternate" href="https://odpf.github.io//firehose/sinks/bigquery-sink" hreflang="x-default"><link rel="stylesheet" href="/firehose/assets/css/styles.620b4533.css">
<link rel="preload" href="/firehose/assets/js/runtime~main.ff7d200d.js" as="script">
<link rel="preload" href="/firehose/assets/js/main.2586b491.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_fXgn">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#222;color:#eee" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="announcementBarContent_xLdY">⭐️ If you like Firehose, give it a star on <a target="_blank" rel="noopener noreferrer" href="https://github.com/odpf/firehose">GitHub</a>! ⭐</div><button type="button" class="clean-btn close announcementBarClose_gvF7" aria-label="Close"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/firehose/"><div class="navbar__logo"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--light_HNdA"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Firehose</b></a></div><div class="navbar__items navbar__items--right"><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/firehose/">Documentation</a><a class="navbar__item navbar__link" href="/firehose/support">Support</a><a href="https://bit.ly/2RzPbtn" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-slack-link"></a><a href="https://github.com/odpf/firehose" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar-item-github"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/firehose/"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--light_HNdA"><img src="/firehose/firehose.png" alt="Firehose" class="themedImage_ToTc themedImage--dark_i4oU"><b>Firehose</b></a><nav class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/firehose/">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/firehose/guides/create_firehose">Guides</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/create_firehose">Creating Firehose</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/json-based-filters">JSON-based Filters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/jexl-based-filters">JEXL-based Filters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/deployment">Deployment</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/guides/manage">Troubleshooting</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/firehose/sinks/http-sink">Sinks</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/http-sink">HTTP</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/grpc-sink">GRPC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/jdbc-sink">JDBC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/firehose/sinks/bigquery-sink">BigQuery</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/influxdb-sink">InfluxDB</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/prometheus-sink">Prometheus</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/mongo-sink">MongoDB</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/redis-sink">Redis</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/elasticsearch-sink">Elasticsearch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/firehose/sinks/blob-sink">Blob</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/firehose/concepts/overview">Concepts</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/firehose/advance/generic">Advance</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/firehose/reference/metrics">Reference</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/firehose/contribute/contribution">Contribute</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/firehose/roadmap">Roadmap</a></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_GujU"><div class="docItemContainer_Adtb"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_aoJ5"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>BigQuery</h1><p>Bigquery Sink has several responsibilities, first creation of bigquery table and dataset when they are not exist, second update the bigquery table schema based on the latest protobuf schema, third translate protobuf messages into bigquery records and insert them to bigquery tables.
Bigquery utilise Bigquery <a href="https://cloud.google.com/bigquery/streaming-data-into-bigquery" target="_blank" rel="noopener noreferrer">Streaming API</a> to insert record into bigquery tables.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="asynchronous-consumer-mode">Asynchronous consumer mode<a class="hash-link" href="#asynchronous-consumer-mode" title="Direct link to heading">​</a></h2><p>Bigquery Streaming API limits size of payload sent for each insert operations. The limitation reduces the amount of message allowed to be inserted when the message size is big.
This will reduce the throughput of bigquery sink. To increase the throughput, firehose provide kafka consumer asynchronous mode.
In asynchronous mode sink operation is executed asynchronously, so multiple sink task can be scheduled and run concurrently.
Throughput can be increased by increasing the number of sink pool.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="at-least-once-guarantee">At Least Once Guarantee<a class="hash-link" href="#at-least-once-guarantee" title="Direct link to heading">​</a></h2><p>Because of asynchronous consumer mode and the possibility of retry on the insert operation. There is no guarantee of the message order that successfully sent to the sink.
That also happened with commit offset, the there is no order of the offset number of the processed messages.
Firehose collect all the offset sort them and only commit the latest continuous offset.
This will ensure all the offset being committed after messages successfully processed even when some messages are being re processed by retry handler or when the insert operation took a long time.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="bigquery-table-schema-update">Bigquery table schema update<a class="hash-link" href="#bigquery-table-schema-update" title="Direct link to heading">​</a></h2><p>Bigquery Sink update the bigquery table schema on separate table update operation. Bigquery utilise <a href="https://github.com/odpf/stencil" target="_blank" rel="noopener noreferrer">Stencil</a> to parse protobuf messages generate schema and update bigquery tables with the latest schema.
The stencil client periodically reload the descriptor cache. Table schema update happened after the descriptor caches uploaded.
Because firehose is horizontally scalable multiple firehose consumer might be running.
Because there is no coordination strategy between consumers the schema update will be triggered by all consumers.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="protobuf-and-bigquery-table-type-mapping">Protobuf and BigQuery table type mapping<a class="hash-link" href="#protobuf-and-bigquery-table-type-mapping" title="Direct link to heading">​</a></h2><p>Here are type conversion between protobuf type and bigquery type :</p><table><thead><tr><th>Protobuf Type</th><th>Bigquery Type</th></tr></thead><tbody><tr><td>bytes</td><td>BYTES</td></tr><tr><td>string</td><td>STRING</td></tr><tr><td>enum</td><td>STRING</td></tr><tr><td>float</td><td>FLOAT</td></tr><tr><td>double</td><td>FLOAT</td></tr><tr><td>bool</td><td>BOOLEAN</td></tr><tr><td>int64, uint64, int32, uint32, fixed64, fixed32, sfixed64, sfixed32, sint64, sint32</td><td>INTEGER</td></tr><tr><td>message</td><td>RECORD</td></tr><tr><td>.google.protobuf.Timestamp</td><td>TIMESTAMP</td></tr><tr><td>.google.protobuf.Struct</td><td>STRING (Json Serialised)</td></tr><tr><td>.google.protobuf.Duration</td><td>RECORD</td></tr></tbody></table><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="modifier">Modifier<a class="hash-link" href="#modifier" title="Direct link to heading">​</a></h2><table><thead><tr><th>Protobuf Modifier</th><th>Bigquery Modifier</th></tr></thead><tbody><tr><td>repeated</td><td>REPEATED</td></tr></tbody></table><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="partitioning">Partitioning<a class="hash-link" href="#partitioning" title="Direct link to heading">​</a></h2><p>Bigquery Sink supports creation of table with partition configuration. Currently, Bigquery Sink only supports time based partitioning.
To have time based partitioning protobuf <code>Timestamp</code> as field is needed on the protobuf message. The protobuf field will be used as partitioning column on table creation.
The time partitioning type that is currently supported is <code>DAY</code> partitioning.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="kafka-metadata">Kafka Metadata<a class="hash-link" href="#kafka-metadata" title="Direct link to heading">​</a></h2><p>For data quality checking purpose sometimes kafka metadata need to be added on the record. When <code>SINK_BIGQUERY_METADATA_NAMESPACE</code> is configured kafka metadata column will be added, here is the list of kafka metadata column to be added :</p><table><thead><tr><th>Fully Qualified Column Name</th><th>Type</th><th>Modifier</th></tr></thead><tbody><tr><td>metadata_column</td><td>RECORD</td><td>NULLABLE</td></tr><tr><td>metadata_column.message_partition</td><td>INTEGER</td><td>NULLABLE</td></tr><tr><td>metadata_column.message_offset</td><td>INTEGER</td><td>NULLABLE</td></tr><tr><td>metadata_column.message_topic</td><td>STRING</td><td>NULLABLE</td></tr><tr><td>metadata_column.message_timestamp</td><td>TIMESTAMP</td><td>NULLABLE</td></tr><tr><td>metadata_column.load_time</td><td>TIMESTAMP</td><td>NULLABLE</td></tr></tbody></table><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="error-handling">Error handling<a class="hash-link" href="#error-handling" title="Direct link to heading">​</a></h2><p>Firehose consumer parse errors from table insertion, translate the error into generic error types and attach them for each message that failed to be inserted to bigquery.
Users can configure how to handle each generic error types accordingly.
Here is mapping of the error translation to generic firehose error types :</p><table><thead><tr><th>Error Name</th><th>Generic Error Type</th><th>Description</th></tr></thead><tbody><tr><td>Stopped Error</td><td>SINK_5XX_ERROR</td><td>Error on a row insertion that happened because insert job is cancelled because other record is invalid although current record is valid</td></tr><tr><td>Out of bounds Error</td><td>SINK_4XX_ERROR</td><td>Error on a row insertion the partitioned column has a date value less than 5 years and more than 1 year in the future</td></tr><tr><td>Invalid schema Error</td><td>SINK_4XX_ERROR</td><td>Error on a row insertion when there is a new field that is not exist on the table or when there is required field on the table</td></tr><tr><td>Other Error</td><td>SINK_UNKNOWN_ERROR</td><td>Uncategorized error</td></tr></tbody></table><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="google-cloud-bigquery-iam-permission">Google Cloud Bigquery IAM Permission<a class="hash-link" href="#google-cloud-bigquery-iam-permission" title="Direct link to heading">​</a></h2><p>Several IAM permission is required for bigquery sink to run properly,</p><ul><li>Create and update Dataset<ul><li>bigquery.tables.create</li><li>bigquery.tables.get</li><li>bigquery.tables.update</li></ul></li><li>Create and update Table<ul><li>bigquery.datasets.create</li><li>bigquery.datasets.get</li><li>bigquery.datasets.update</li></ul></li><li>Stream insert to Table<ul><li>bigquery.tables.updateData</li></ul></li></ul><p>Further documentation on bigquery IAM permission <a href="https://cloud.google.com/bigquery/streaming-data-into-bigquery" target="_blank" rel="noopener noreferrer">here</a>.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="configurations">Configurations<a class="hash-link" href="#configurations" title="Direct link to heading">​</a></h2><p>A Bigquery sink Firehose <!-- -->(<code>SINK_TYPE</code>=<code>bigquery</code>)<!-- --> requires the following variables to be set along with Generic ones</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_google_cloud_project_id"><code>SINK_BIGQUERY_GOOGLE_CLOUD_PROJECT_ID</code><a class="hash-link" href="#sink_bigquery_google_cloud_project_id" title="Direct link to heading">​</a></h3><p>Contains information of google cloud project id location of the bigquery table where the records need to be inserted. Further documentation on google cloud <a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects" target="_blank" rel="noopener noreferrer">project id</a>.</p><ul><li>Example value: <code>gcp-project-id</code></li><li>Type: <code>required</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_table_name"><code>SINK_BIGQUERY_TABLE_NAME</code><a class="hash-link" href="#sink_bigquery_table_name" title="Direct link to heading">​</a></h3><p>The name of bigquery table. Here is further documentation of bigquery <a href="https://cloud.google.com/bigquery/docs/tables" target="_blank" rel="noopener noreferrer">table naming</a>.</p><ul><li>Example value: <code>user_profile</code></li><li>Type: <code>required</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_dataset_name"><code>SINK_BIGQUERY_DATASET_NAME</code><a class="hash-link" href="#sink_bigquery_dataset_name" title="Direct link to heading">​</a></h3><p>The name of dataset that contains the bigquery table. Here is further documentation of bigquery <a href="https://cloud.google.com/bigquery/docs/datasets" target="_blank" rel="noopener noreferrer">dataset naming</a>.</p><ul><li>Example value: <code>customer</code></li><li>Type: <code>required</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_dataset_labels"><code>SINK_BIGQUERY_DATASET_LABELS</code><a class="hash-link" href="#sink_bigquery_dataset_labels" title="Direct link to heading">​</a></h3><p>Labels of a bigquery dataset, key-value information separated by comma attached to the bigquery dataset. This configuration define labels that will be set to the bigquery dataset. Here is further documentation of bigquery <a href="https://cloud.google.com/bigquery/docs/labels-intro" target="_blank" rel="noopener noreferrer">labels</a>.</p><ul><li>Example value: <code>owner=data-engineering,granurality=daily</code></li><li>Type: <code>optional</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_table_labels"><code>SINK_BIGQUERY_TABLE_LABELS</code><a class="hash-link" href="#sink_bigquery_table_labels" title="Direct link to heading">​</a></h3><p>Labels of a bigquery table, key-value information separated by comma attached to the bigquery table. This configuration define labels that will be set to the bigquery dataset. Here is further documentation of bigquery <a href="https://cloud.google.com/bigquery/docs/labels-intro" target="_blank" rel="noopener noreferrer">labels</a>.</p><ul><li>Example value: <code>owner=data-engineering,granurality=daily</code></li><li>Type: <code>optional</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_table_partitioning_enable"><code>SINK_BIGQUERY_TABLE_PARTITIONING_ENABLE</code><a class="hash-link" href="#sink_bigquery_table_partitioning_enable" title="Direct link to heading">​</a></h3><p>Configuration for enable table partitioning. This config will be used for provide partitioning config when creating the bigquery table.
Bigquery table partitioning config can only be set once, on the table creation and the partitioning cannot be disabled once created. Changing this value of this config later will cause error when firehose trying to update the bigquery table.
Here is further documentation of bigquery <a href="https://cloud.google.com/bigquery/docs/partitioned-tables" target="_blank" rel="noopener noreferrer">table partitioning</a>.</p><ul><li>Example value: <code>true</code></li><li>Type: <code>required</code></li><li>Default value: <code>false</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_table_partition_key"><code>SINK_BIGQUERY_TABLE_PARTITION_KEY</code><a class="hash-link" href="#sink_bigquery_table_partition_key" title="Direct link to heading">​</a></h3><p>Define protobuf/bigquery field name that will be used for bigquery table partitioning. only protobuf <code>Timestamp</code> field, that later converted into bigquery <code>Timestamp</code> column that is supported as partitioning key.
Currently, this sink only support <code>DAY</code> time partitioning type.
Here is further documentation of bigquery <a href="https://cloud.google.com/bigquery/docs/creating-partitioned-tables#console" target="_blank" rel="noopener noreferrer">column time partitioning</a>.</p><ul><li>Example value: <code>event_timestamp</code></li><li>Type: <code>required</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_row_insert_id_enable"><code>SINK_BIGQUERY_ROW_INSERT_ID_ENABLE</code><a class="hash-link" href="#sink_bigquery_row_insert_id_enable" title="Direct link to heading">​</a></h3><p>This config enables adding of ID row intended for deduplication when inserting new records into bigquery.
Here is further documentation of bigquery streaming insert <a href="https://cloud.google.com/bigquery/streaming-data-into-bigquery" target="_blank" rel="noopener noreferrer">deduplication</a>.</p><ul><li>Example value: <code>false</code></li><li>Type: <code>required</code></li><li>Default value: <code>true</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_credential_path"><code>SINK_BIGQUERY_CREDENTIAL_PATH</code><a class="hash-link" href="#sink_bigquery_credential_path" title="Direct link to heading">​</a></h3><p>Full path of google cloud credentials file. Here is further documentation of google cloud authentication and <a href="https://cloud.google.com/docs/authentication/getting-started" target="_blank" rel="noopener noreferrer">credentials</a>.</p><ul><li>Example value: <code>/.secret/google-cloud-credentials.json</code></li><li>Type: <code>required</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_metadata_namespace"><code>SINK_BIGQUERY_METADATA_NAMESPACE</code><a class="hash-link" href="#sink_bigquery_metadata_namespace" title="Direct link to heading">​</a></h3><p>The name of column that will be added alongside of the existing bigquery column that generated from protobuf, that column contains struct of kafka metadata of the inserted record.
When this config is not configured the metadata column will not be added to the table.</p><ul><li>Example value: <code>kafka_metadata</code></li><li>Type: <code>optional</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_dataset_location"><code>SINK_BIGQUERY_DATASET_LOCATION</code><a class="hash-link" href="#sink_bigquery_dataset_location" title="Direct link to heading">​</a></h3><p>The geographic region name of location of bigquery dataset. Further documentation on bigquery dataset <a href="https://cloud.google.com/bigquery/docs/locations#dataset_location" target="_blank" rel="noopener noreferrer">location</a>.</p><ul><li>Example value: <code>us-central1</code></li><li>Type: <code>optional</code></li><li>Default value: <code>asia-southeast1</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_table_partition_expiry_ms"><code>SINK_BIGQUERY_TABLE_PARTITION_EXPIRY_MS</code><a class="hash-link" href="#sink_bigquery_table_partition_expiry_ms" title="Direct link to heading">​</a></h3><p>The duration of bigquery table partitioning expiration in milliseconds. Fill this config with <code>-1</code> will disable the table partition expiration. Further documentation on bigquery table partition <a href="https://cloud.google.com/bigquery/docs/managing-partitioned-tables#partition-expiration" target="_blank" rel="noopener noreferrer">expiration</a>.</p><ul><li>Example value: <code>2592000000</code></li><li>Type: <code>optional</code></li><li>Default value: <code>-1</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_client_read_timeout_ms"><code>SINK_BIGQUERY_CLIENT_READ_TIMEOUT_MS</code><a class="hash-link" href="#sink_bigquery_client_read_timeout_ms" title="Direct link to heading">​</a></h3><p>The duration of bigquery client http read timeout in milliseconds, 0 for an infinite timeout, a negative number for the default value (20000).</p><ul><li>Example value: <code>20000</code></li><li>Type: <code>optional</code></li><li>Default value: <code>-1</code></li></ul><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="sink_bigquery_client_connect_timeout_ms"><code>SINK_BIGQUERY_CLIENT_CONNECT_TIMEOUT_MS</code><a class="hash-link" href="#sink_bigquery_client_connect_timeout_ms" title="Direct link to heading">​</a></h3><p>The duration of bigquery client http connection timeout in milliseconds, 0 for an infinite timeout, a negative number for the default value (20000).</p><ul><li>Example value: <code>20000</code></li><li>Type: <code>optional</code></li><li>Default value: <code>-1</code></li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/odpf/firehose/edit/master/docs/docs/sinks/bigquery-sink.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_eYIM" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vbeJ"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/firehose/sinks/jdbc-sink"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">JDBC</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/firehose/sinks/influxdb-sink"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">InfluxDB</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#asynchronous-consumer-mode" class="table-of-contents__link toc-highlight">Asynchronous consumer mode</a></li><li><a href="#at-least-once-guarantee" class="table-of-contents__link toc-highlight">At Least Once Guarantee</a></li><li><a href="#bigquery-table-schema-update" class="table-of-contents__link toc-highlight">Bigquery table schema update</a></li><li><a href="#protobuf-and-bigquery-table-type-mapping" class="table-of-contents__link toc-highlight">Protobuf and BigQuery table type mapping</a></li><li><a href="#modifier" class="table-of-contents__link toc-highlight">Modifier</a></li><li><a href="#partitioning" class="table-of-contents__link toc-highlight">Partitioning</a></li><li><a href="#kafka-metadata" class="table-of-contents__link toc-highlight">Kafka Metadata</a></li><li><a href="#error-handling" class="table-of-contents__link toc-highlight">Error handling</a></li><li><a href="#google-cloud-bigquery-iam-permission" class="table-of-contents__link toc-highlight">Google Cloud Bigquery IAM Permission</a></li><li><a href="#configurations" class="table-of-contents__link toc-highlight">Configurations</a><ul><li><a href="#sink_bigquery_google_cloud_project_id" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_GOOGLE_CLOUD_PROJECT_ID</code></a></li><li><a href="#sink_bigquery_table_name" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_TABLE_NAME</code></a></li><li><a href="#sink_bigquery_dataset_name" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_DATASET_NAME</code></a></li><li><a href="#sink_bigquery_dataset_labels" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_DATASET_LABELS</code></a></li><li><a href="#sink_bigquery_table_labels" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_TABLE_LABELS</code></a></li><li><a href="#sink_bigquery_table_partitioning_enable" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_TABLE_PARTITIONING_ENABLE</code></a></li><li><a href="#sink_bigquery_table_partition_key" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_TABLE_PARTITION_KEY</code></a></li><li><a href="#sink_bigquery_row_insert_id_enable" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_ROW_INSERT_ID_ENABLE</code></a></li><li><a href="#sink_bigquery_credential_path" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_CREDENTIAL_PATH</code></a></li><li><a href="#sink_bigquery_metadata_namespace" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_METADATA_NAMESPACE</code></a></li><li><a href="#sink_bigquery_dataset_location" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_DATASET_LOCATION</code></a></li><li><a href="#sink_bigquery_table_partition_expiry_ms" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_TABLE_PARTITION_EXPIRY_MS</code></a></li><li><a href="#sink_bigquery_client_read_timeout_ms" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_CLIENT_READ_TIMEOUT_MS</code></a></li><li><a href="#sink_bigquery_client_connect_timeout_ms" class="table-of-contents__link toc-highlight"><code>SINK_BIGQUERY_CLIENT_CONNECT_TIMEOUT_MS</code></a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Open DataOps Foundation © 2022</div></div></div></footer></div>
<script src="/firehose/assets/js/runtime~main.ff7d200d.js"></script>
<script src="/firehose/assets/js/main.2586b491.js"></script>
</body>
</html>